#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Pandoc Wordæ–‡æ¡£å¤„ç†å·¥å…· - å¢å¼ºç‰ˆ (æ”¯æŒç‰¹æ®Šæ ¼å¼è¯†åˆ«)

ä½¿ç”¨pandocå°†Wordæ–‡æ¡£è½¬æ¢ä¸ºæ¨¡å‹å¯è¯»çš„çº¯æ–‡æœ¬å†…å®¹ï¼Œæ”¯æŒï¼š
1. æ–‡æ¡£æ–‡æœ¬è½¬æ¢ (Pandoc)
2. å›¾ç‰‡æå–å’Œå†…å®¹åˆ†æ (LLM Vision)
3. æ°´å°æ–‡å­—æ›¿æ¢
4. å¤§æ¨¡å‹APIè°ƒç”¨ (æ–‡æ¡£ç»“æ„è§£æ)
5. ğŸ†• ç‰¹æ®Šæ ¼å¼è¯†åˆ« (æ³¢æµªçº¿ã€ä¸‹åˆ’çº¿ã€ä¸Šæ ‡ä¸‹æ ‡ç­‰)
6. ğŸ†• ç€é‡å·æ£€æµ‹ (åŠ ç‚¹å­—)
7. ğŸ†• å­—ä½“æ ·å¼åˆ†æ (é¢œè‰²ã€å­—ä½“ã€å­—å·)
8. ğŸ†• æ ¼å¼ç»Ÿè®¡æŠ¥å‘Š

ä¾èµ–å®‰è£…ï¼š
1. ç¡®ä¿ç³»ç»Ÿå·²å®‰è£…pandoc: https://pandoc.org/installing.html
2. å®‰è£…python-docx: pip install python-docx
3. å®‰è£…å…¶ä»–ä¾èµ–: pip install pillow requests

ä½¿ç”¨æ–¹æ³•ï¼š
1. è¿è¡Œè„šæœ¬å¤„ç†Wordæ–‡æ¡£
2. è‡ªåŠ¨æå–å›¾ç‰‡å¹¶ä½¿ç”¨LLMåˆ†æå†…å®¹
3. è¯†åˆ«æ–‡æ¡£ä¸­çš„ç‰¹æ®Šæ ¼å¼ï¼ˆæ³¢æµªçº¿ã€ä¸‹åˆ’çº¿ç­‰ï¼‰
4. ç”ŸæˆåŒ…å«æ ¼å¼ä¿¡æ¯çš„è§£æç»“æœ
5. ä¿å­˜æ ¼å¼åˆ†ææŠ¥å‘Š
"""

import subprocess
import requests
import json
import time
import os
import re
import zipfile
import tempfile
from datetime import datetime
from pathlib import Path
from PIL import Image
import base64
from io import BytesIO
from collections import defaultdict

# æ–°å¢ï¼šç‰¹æ®Šæ ¼å¼è¯†åˆ«ä¾èµ–
try:
    from docx import Document
    from docx.enum.text import WD_UNDERLINE
    from docx.oxml.ns import qn
    DOCX_AVAILABLE = True
    print("âœ… python-docxåº“å¯ç”¨ï¼Œæ”¯æŒç‰¹æ®Šæ ¼å¼è¯†åˆ«")
except ImportError:
    DOCX_AVAILABLE = False
    print("âš ï¸ python-docxåº“ä¸å¯ç”¨ï¼Œå°†è·³è¿‡ç‰¹æ®Šæ ¼å¼è¯†åˆ«åŠŸèƒ½")
    print("   å®‰è£…å‘½ä»¤: pip install python-docx")

class PandocWordProcessor:
    def __init__(self):
        self.api_key = "baf9ea42-7e17-4df6-9a22-90127ac8220e"
        self.base_url = "https://ark.cn-beijing.volces.com/api"
        
        # æ£€æŸ¥pandocæ˜¯å¦å¯ç”¨
        self.pandoc_available = self._check_pandoc()
        if not self.pandoc_available:
            print("âš ï¸ è­¦å‘Š: pandocæœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­")
            print("è¯·è®¿é—® https://pandoc.org/installing.html å®‰è£…pandoc")
        
        # æ–°å¢ï¼šç‰¹æ®Šæ ¼å¼è¯†åˆ«åŠŸèƒ½åˆå§‹åŒ–
        self.format_detection_enabled = DOCX_AVAILABLE
        self.special_formatted_text = []
        self.format_statistics = defaultdict(int)
        
        if self.format_detection_enabled:
            self._init_format_styles()
    
    def _check_pandoc(self):
        """æ£€æŸ¥pandocæ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(['pandoc', '--version'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                print(f"âœ… Pandocå¯ç”¨: {result.stdout.split()[1]}")
                return True
            else:
                print(f"âŒ Pandocæ£€æŸ¥å¤±è´¥: {result.stderr}")
                return False
        except FileNotFoundError:
            print("âŒ æœªæ‰¾åˆ°pandocå‘½ä»¤")
            return False
        except subprocess.TimeoutExpired:
            print("âŒ Pandocæ£€æŸ¥è¶…æ—¶")
            return False
        except Exception as e:
            print(f"âŒ Pandocæ£€æŸ¥å¼‚å¸¸: {e}")
            return False
    
    def _init_format_styles(self):
        """åˆå§‹åŒ–æ ¼å¼æ ·å¼æ˜ å°„"""
        if not DOCX_AVAILABLE:
            return
        
        # ä¸‹åˆ’çº¿æ ·å¼æ˜ å°„ - å®‰å…¨åœ°æ·»åŠ ä¸‹åˆ’çº¿æ ·å¼
        self.underline_styles = {}
        styles_to_add = [
            (getattr(WD_UNDERLINE, 'SINGLE', None), "å•ä¸‹åˆ’çº¿"),
            (getattr(WD_UNDERLINE, 'DOUBLE', None), "åŒä¸‹åˆ’çº¿"),
            (getattr(WD_UNDERLINE, 'THICK', None), "ç²—ä¸‹åˆ’çº¿"),
            (getattr(WD_UNDERLINE, 'DOTTED', None), "ç‚¹çŠ¶ä¸‹åˆ’çº¿"),
            (getattr(WD_UNDERLINE, 'DASH', None), "è™šçº¿ä¸‹åˆ’çº¿"),
            (getattr(WD_UNDERLINE, 'DOT_DASH', None), "ç‚¹åˆ’çº¿ä¸‹åˆ’çº¿"),
            (getattr(WD_UNDERLINE, 'DOT_DOT_DASH', None), "ç‚¹ç‚¹åˆ’çº¿ä¸‹åˆ’çº¿"),
            (getattr(WD_UNDERLINE, 'WAVY', None), "æ³¢æµªçº¿ä¸‹åˆ’çº¿"),
            (getattr(WD_UNDERLINE, 'DOTTED_HEAVY', None), "ç²—ç‚¹çŠ¶ä¸‹åˆ’çº¿"),
            (getattr(WD_UNDERLINE, 'DASH_HEAVY', None), "ç²—è™šçº¿ä¸‹åˆ’çº¿"),
            (getattr(WD_UNDERLINE, 'WAVY_HEAVY', None), "ç²—æ³¢æµªçº¿ä¸‹åˆ’çº¿"),
            (getattr(WD_UNDERLINE, 'WAVY_DOUBLE', None), "åŒæ³¢æµªçº¿ä¸‹åˆ’çº¿")
        ]
        
        for style_enum, style_name in styles_to_add:
            if style_enum is not None:
                self.underline_styles[style_enum] = style_name
        
        print(f"ğŸ“‹ åˆå§‹åŒ–äº† {len(self.underline_styles)} ç§ä¸‹åˆ’çº¿æ ·å¼è¯†åˆ«")
    
    def _analyze_text_formatting(self, run, para_index=0, run_index=0):
        """åˆ†ææ–‡æœ¬ç‰‡æ®µçš„æ ¼å¼"""
        if not DOCX_AVAILABLE:
            return []
        
        formats = []
        font = run.font
        
        # ä¸‹åˆ’çº¿æ£€æŸ¥
        if font.underline:
            underline_style = self.underline_styles.get(font.underline, f"æœªçŸ¥ä¸‹åˆ’çº¿æ ·å¼({font.underline})")
            formats.append(f"ä¸‹åˆ’çº¿: {underline_style}")
            
            # ç‰¹åˆ«æ ‡è®°æ³¢æµªçº¿å’Œç‚¹çŠ¶çº¿
            wavy_styles = [style for style in [
                getattr(WD_UNDERLINE, 'WAVY', None),
                getattr(WD_UNDERLINE, 'WAVY_HEAVY', None),
                getattr(WD_UNDERLINE, 'WAVY_DOUBLE', None)
            ] if style is not None]
            
            dotted_styles = [style for style in [
                getattr(WD_UNDERLINE, 'DOTTED', None),
                getattr(WD_UNDERLINE, 'DOTTED_HEAVY', None)
            ] if style is not None]
            
            if font.underline in wavy_styles:
                formats.append("âš ï¸ æ³¢æµªçº¿æ ¼å¼")
            elif font.underline in dotted_styles:
                formats.append("âš ï¸ ç‚¹çŠ¶çº¿æ ¼å¼")
        
        # ä¸Šæ ‡ä¸‹æ ‡
        if font.superscript:
            formats.append("ä¸Šæ ‡")
        if font.subscript:
            formats.append("ä¸‹æ ‡")
        
        # åˆ é™¤çº¿
        if font.strike:
            formats.append("åˆ é™¤çº¿")
        
        # ç²—ä½“æ–œä½“
        if font.bold:
            formats.append("ç²—ä½“")
        if font.italic:
            formats.append("æ–œä½“")
        
        # å­—ä½“é¢œè‰²
        if font.color and font.color.rgb:
            try:
                rgb_val = font.color.rgb
                if hasattr(rgb_val, '__int__'):
                    color_hex = f"#{int(rgb_val):06x}"
                else:
                    color_hex = str(rgb_val)
                formats.append(f"å­—ä½“é¢œè‰²: {color_hex}")
            except Exception:
                formats.append("å­—ä½“é¢œè‰²: ç‰¹æ®Šé¢œè‰²")
        
        # å­—ä½“å¤§å°
        if font.size:
            try:
                size_pt = font.size.pt
                formats.append(f"å­—å·: {size_pt}ç£…")
            except:
                formats.append("å­—å·: è‡ªå®šä¹‰å¤§å°")
        
        # å­—ä½“åç§°
        if font.name:
            formats.append(f"å­—ä½“: {font.name}")
        
        # æ£€æŸ¥ç€é‡å·
        emphasis_mark = self._check_emphasis_mark(run)
        if emphasis_mark:
            formats.append(f"ç€é‡å·: {emphasis_mark}")
        
        # ç»Ÿè®¡æ ¼å¼ä½¿ç”¨
        for fmt in formats:
            self.format_statistics[fmt] += 1
        
        # ä¿å­˜ç‰¹æ®Šæ ¼å¼çš„æ–‡æœ¬
        if formats and run.text.strip():
            self.special_formatted_text.append({
                'text': run.text,
                'paragraph': para_index,
                'run': run_index,
                'formats': formats
            })
        
        return formats
    
    def _check_emphasis_mark(self, run):
        """æ£€æŸ¥ç€é‡å·ï¼ˆåŠ ç‚¹å­—ï¼‰"""
        try:
            run_xml = run._element
            em_elements = run_xml.xpath('.//w:em', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'})
            
            if em_elements:
                em_val = em_elements[0].get(qn('w:val'))
                emphasis_types = {
                    'dot': 'ç‚¹',
                    'comma': 'é€—å·',
                    'circle': 'åœ†åœˆ',
                    'underDot': 'ä¸‹ç‚¹'
                }
                return emphasis_types.get(em_val, f'ç€é‡å·({em_val})')
        except:
            pass
        
        return None
    
    def extract_format_analysis(self, docx_path):
        """æå–æ–‡æ¡£çš„æ ¼å¼åˆ†æä¿¡æ¯"""
        if not self.format_detection_enabled:
            print("ğŸš« æ ¼å¼æ£€æµ‹åŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡æ ¼å¼åˆ†æ")
            return None
        
        print("ğŸ” å¼€å§‹åˆ†ææ–‡æ¡£æ ¼å¼...")
        
        try:
            doc = Document(docx_path)
            paragraph_count = 0
            
            # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
            self.special_formatted_text = []
            self.format_statistics = defaultdict(int)
            
            for para in doc.paragraphs:
                paragraph_count += 1
                for run_index, run in enumerate(para.runs):
                    self._analyze_text_formatting(run, paragraph_count, run_index)
            
            # åˆ†æè¡¨æ ¼
            table_count = 0
            for table in doc.tables:
                table_count += 1
                for row_index, row in enumerate(table.rows):
                    for cell_index, cell in enumerate(row.cells):
                        for para in cell.paragraphs:
                            for run_index, run in enumerate(para.runs):
                                location = f"è¡¨æ ¼{table_count}-è¡Œ{row_index}-åˆ—{cell_index}"
                                self._analyze_text_formatting(run, location, run_index)
            
            print(f"âœ… æ ¼å¼åˆ†æå®Œæˆ: {paragraph_count}ä¸ªæ®µè½, {table_count}ä¸ªè¡¨æ ¼")
            print(f"ğŸ“Š å‘ç° {len(self.special_formatted_text)} ä¸ªåŒ…å«ç‰¹æ®Šæ ¼å¼çš„æ–‡æœ¬ç‰‡æ®µ")
            
            return {
                'total_paragraphs': paragraph_count,
                'total_tables': table_count,
                'special_format_count': len(self.special_formatted_text),
                'format_statistics': dict(self.format_statistics)
            }
            
        except Exception as e:
            print(f"âŒ æ ¼å¼åˆ†æå¤±è´¥: {e}")
            return None
    
    def _save_format_analysis(self, format_analysis, file_path):
        """ä¿å­˜æ ¼å¼åˆ†æç»“æœ"""
        try:
            # åˆ›å»ºæ ¼å¼åˆ†æç»“æœç›®å½•
            format_dir = Path("format_analysis")
            format_dir.mkdir(exist_ok=True)
            
            doc_name = Path(file_path).stem
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ä¿å­˜æ ¼å¼ç»Ÿè®¡æ‘˜è¦
            summary_file = format_dir / f"format_summary_{doc_name}_{timestamp}.txt"
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write(f"æ–‡æ¡£æ ¼å¼åˆ†ææŠ¥å‘Š\n")
                f.write(f"æ–‡æ¡£: {file_path}\n")
                f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"=" * 50 + "\n\n")
                
                f.write("æ ¼å¼ç»Ÿè®¡:\n")
                for fmt, count in format_analysis['format_statistics'].items():
                    f.write(f"  {fmt}: {count}æ¬¡\n")
                
                f.write(f"\nç‰¹æ®Šæ ¼å¼æ–‡æœ¬è¯¦æƒ…:\n")
                for item in self.special_formatted_text:
                    f.write(f"\nä½ç½®{item['paragraph']}-ç‰‡æ®µ{item['run']}: \"{item['text'][:100]}{'...' if len(item['text']) > 100 else ''}\"\n")
                    for fmt in item['formats']:
                        f.write(f"  â””â”€ {fmt}\n")
            
            print(f"ğŸ“‹ æ ¼å¼åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {summary_file}")
            
            # ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†æ•°æ®
            json_file = format_dir / f"format_details_{doc_name}_{timestamp}.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'document_path': file_path,
                    'analysis_summary': format_analysis,
                    'special_formatted_text': self.special_formatted_text,
                    'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ è¯¦ç»†æ ¼å¼æ•°æ®å·²ä¿å­˜: {json_file}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ ¼å¼åˆ†æç»“æœå¤±è´¥: {e}")
    
    def _integrate_format_info(self, api_result, format_analysis, file_path):
        """å°†æ ¼å¼ä¿¡æ¯æ•´åˆåˆ°APIç»“æœä¸­"""
        try:
            # ä¸ºAPIç»“æœæ·»åŠ æ ¼å¼åˆ†æä¿¡æ¯
            if isinstance(api_result, list):
                # ä¸ºæ¯ä¸ªé¢˜ç›®æ·»åŠ æ ¼å¼ä¿¡æ¯æ¦‚è¦
                format_summary = {
                    'total_special_formats': len(self.special_formatted_text),
                    'format_types': list(format_analysis['format_statistics'].keys()),
                    'analysis_enabled': True
                }
                
                # å°è¯•åŒ¹é…ç‰¹æ®Šæ ¼å¼æ–‡æœ¬åˆ°å…·ä½“é¢˜ç›®
                for question in api_result:
                    question['format_info'] = format_summary.copy()
                    question['special_formats_in_question'] = []
                    
                    # æ£€æŸ¥é¢˜ç›®å†…å®¹æ˜¯å¦åŒ…å«ç‰¹æ®Šæ ¼å¼çš„æ–‡æœ¬
                    question_text = question.get('question', {}).get('content', '')
                    for format_item in self.special_formatted_text:
                        if format_item['text'].strip() in question_text:
                            question['special_formats_in_question'].append({
                                'text': format_item['text'],
                                'formats': format_item['formats']
                            })
            
            print(f"ğŸ”— æ ¼å¼ä¿¡æ¯å·²æ•´åˆåˆ°APIç»“æœä¸­")
            
        except Exception as e:
            print(f"âš ï¸ æ•´åˆæ ¼å¼ä¿¡æ¯å¤±è´¥: {e}")
    
    def get_special_format_summary(self):
        """è·å–ç‰¹æ®Šæ ¼å¼æ‘˜è¦ä¿¡æ¯"""
        if not self.format_detection_enabled:
            return "æ ¼å¼æ£€æµ‹åŠŸèƒ½æœªå¯ç”¨"
        
        if not self.special_formatted_text:
            return "æœªå‘ç°ç‰¹æ®Šæ ¼å¼æ–‡æœ¬"
        
        summary = []
        summary.append(f"ğŸ“Š ç‰¹æ®Šæ ¼å¼ç»Ÿè®¡ (æ€»è®¡: {len(self.special_formatted_text)} ä¸ªç‰‡æ®µ):")
        
        # æŒ‰æ ¼å¼ç±»å‹ç»Ÿè®¡
        format_counts = defaultdict(int)
        for item in self.special_formatted_text:
            for fmt in item['formats']:
                if 'âš ï¸' in fmt:  # é‡ç‚¹å…³æ³¨çš„æ ¼å¼
                    format_counts[fmt] += 1
        
        for fmt, count in sorted(format_counts.items(), key=lambda x: x[1], reverse=True):
            summary.append(f"  {fmt}: {count}æ¬¡")
        
        return "\n".join(summary)
    
    def get_supported_formats(self):
        """è·å–æ”¯æŒçš„æ–‡æ¡£æ ¼å¼"""
        return ['.docx', '.doc', '.rtf', '.odt', '.txt']
    
    def is_supported_format(self, file_path):
        """æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ"""
        file_ext = Path(file_path).suffix.lower()
        return file_ext in self.get_supported_formats()
    
    def extract_images_from_docx(self, docx_path, save_images=False):
        """ä»docxæ–‡ä»¶ä¸­æå–å›¾ç‰‡"""
        print(f"ğŸ–¼ï¸  ä»docxæ–‡ä»¶ä¸­æå–å›¾ç‰‡...")
        
        images = []
        if save_images:
            # åˆ›å»ºmediaæ–‡ä»¶å¤¹
            media_dir = Path("media")
            media_dir.mkdir(exist_ok=True)
            print(f"ğŸ“ åˆ›å»ºå›¾ç‰‡ä¿å­˜ç›®å½•: {media_dir}")
        
        try:
            # docxæ–‡ä»¶æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªzipæ–‡ä»¶
            with zipfile.ZipFile(docx_path, 'r') as zip_file:
                # æŸ¥æ‰¾mediaæ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡
                for file_info in zip_file.filelist:
                    if file_info.filename.startswith('word/media/'):
                        file_name = file_info.filename.split('/')[-1]
                        file_ext = Path(file_name).suffix.lower()
                        
                        # åªå¤„ç†å›¾ç‰‡æ–‡ä»¶
                        if file_ext in ['.png', '.jpg', '.jpeg', '.gif', '.bmp']:
                            try:
                                # è¯»å–å›¾ç‰‡æ•°æ®
                                with zip_file.open(file_info.filename) as img_file:
                                    img_data = img_file.read()
                                
                                # è½¬æ¢ä¸ºPIL Imageå¯¹è±¡
                                img = Image.open(BytesIO(img_data))
                                
                                # å¦‚æœéœ€è¦ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°
                                if save_images:
                                    img_path = media_dir / file_name
                                    with open(img_path, 'wb') as f:
                                        f.write(img_data)
                                    print(f"  ğŸ’¾ ä¿å­˜å›¾ç‰‡: {img_path}")
                                
                                images.append({
                                    'filename': file_name,
                                    'path': file_info.filename,
                                    'image': img,
                                    'data': img_data,
                                    'size': img.size,
                                    'format': img.format
                                })
                                
                                print(f"  ğŸ“· æå–å›¾ç‰‡: {file_name} ({img.size[0]}x{img.size[1]})")
                                
                            except Exception as e:
                                print(f"  âš ï¸  å›¾ç‰‡ {file_name} è¯»å–å¤±è´¥: {e}")
                                continue
                
                print(f"âœ… å…±æå– {len(images)} å¼ å›¾ç‰‡")
                return images
                
        except Exception as e:
            print(f"âŒ æå–å›¾ç‰‡å¤±è´¥: {e}")
            return []
    
    def analyze_image_with_llm(self, image_data, image_name):
        """ä½¿ç”¨LLMåˆ†æå›¾ç‰‡å†…å®¹"""
        print(f"  ğŸ¤– ä½¿ç”¨LLMåˆ†æå›¾ç‰‡: {image_name}")
        
        try:
            # å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64
            img_buffer = BytesIO()
            if isinstance(image_data, bytes):
                # å¦‚æœå·²ç»æ˜¯bytesï¼Œç›´æ¥ä½¿ç”¨
                img_base64 = base64.b64encode(image_data).decode()
            else:
                # å¦‚æœæ˜¯PIL Imageï¼Œå…ˆä¿å­˜ä¸ºbytes
                image_data.save(img_buffer, format='PNG')
                img_base64 = base64.b64encode(img_buffer.getvalue()).decode()
            
            # æ„å»ºAPIè¯·æ±‚
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            # ä½¿ç”¨vision APIåˆ†æå›¾ç‰‡
            data = {
                "model": "doubao-seed-1-6-250615",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "è¯·åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼Œç”¨ç®€æ´çš„ä¸­æ–‡æè¿°å›¾ç‰‡ä¸­æ˜¾ç¤ºçš„å†…å®¹ã€‚å¦‚æœæ˜¯è¯•å·é¢˜ç›®ï¼Œè¯·æè¿°é¢˜ç›®ç±»å‹å’Œä¸»è¦å†…å®¹ã€‚"
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{img_base64}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 500,
                "temperature": 0.1
            }
            
            # è°ƒç”¨API
            response = requests.post(
                f"{self.base_url}/v3/chat/completions",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    content = result['choices'][0]['message']['content']
                    print(f"  âœ… å›¾ç‰‡åˆ†æå®Œæˆ: {content[:100]}...")
                    return content
                else:
                    print(f"  âš ï¸  APIå“åº”æ ¼å¼å¼‚å¸¸")
                    return f"å›¾ç‰‡å†…å®¹: {image_name}"
            else:
                print(f"  âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return f"å›¾ç‰‡å†…å®¹: {image_name}"
                
        except Exception as e:
            print(f"  âŒ å›¾ç‰‡åˆ†æå¼‚å¸¸: {e}")
            return f"å›¾ç‰‡å†…å®¹: {image_name}"
    
    def replace_image_watermarks(self, content, images):
        """æ›¿æ¢å†…å®¹ä¸­çš„å›¾ç‰‡æ°´å°ä¸ºå›¾ç‰‡å†…å®¹æè¿°"""
        print("ğŸ”„ æ›¿æ¢å›¾ç‰‡æ°´å°...")
        
        if not images:
            print("  â„¹ï¸  æ²¡æœ‰å›¾ç‰‡éœ€è¦å¤„ç†")
            return content
        
        # æŸ¥æ‰¾å›¾ç‰‡å¼•ç”¨æ¨¡å¼
        # åŒ¹é…ç±»ä¼¼ ![å­¦ç§‘ç½‘(www.zxxk.com)--æ•™è‚²èµ„æºé—¨æˆ·...](media/image6.png) çš„æ¨¡å¼
        image_pattern = r'!\[([^\]]+)\]\(([^)]+)\)'
        
        def replace_image_ref(match):
            watermark_text = match.group(1)
            image_path = match.group(2)
            
            # æå–å›¾ç‰‡æ–‡ä»¶å
            image_filename = Path(image_path).name
            
            # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡
            for img_info in images:
                if img_info['filename'] == image_filename:
                    # ä½¿ç”¨LLMåˆ†æå›¾ç‰‡å†…å®¹
                    image_description = self.analyze_image_with_llm(img_info['image'], image_filename)
                    
                    # æ›¿æ¢æ°´å°æ–‡å­—ä¸ºå›¾ç‰‡æè¿°
                    new_text = f"![{image_description}]({image_path})"
                    print(f"  ğŸ”„ æ›¿æ¢: {watermark_text[:50]}... -> {image_description[:50]}...")
                    return new_text
            
            # å¦‚æœæ²¡æ‰¾åˆ°å¯¹åº”å›¾ç‰‡ï¼Œä¿ç•™åŸæ ·
            print(f"  âš ï¸  æœªæ‰¾åˆ°å›¾ç‰‡: {image_filename}")
            return match.group(0)
        
        # æ‰§è¡Œæ›¿æ¢
        modified_content = re.sub(image_pattern, replace_image_ref, content)
        
        # ç»Ÿè®¡æ›¿æ¢æ¬¡æ•°
        original_count = len(re.findall(image_pattern, content))
        modified_count = len(re.findall(image_pattern, modified_content))
        
        print(f"âœ… æ°´å°æ›¿æ¢å®Œæˆï¼Œå¤„ç†äº† {len(images)} å¼ å›¾ç‰‡")
        return modified_content
    
    def convert_word_to_text(self, file_path, output_format='markdown'):
        """ä½¿ç”¨pandocå°†Wordæ–‡æ¡£è½¬æ¢ä¸ºæ–‡æœ¬ï¼Œå¹¶å¢å¼ºæ ¼å¼æ ‡æ³¨"""
        if not self.pandoc_available:
            print("âŒ Pandocä¸å¯ç”¨ï¼Œæ— æ³•å¤„ç†æ–‡æ¡£")
            return None
        
        if not self.is_supported_format(file_path):
            print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {Path(file_path).suffix}")
            print(f"æ”¯æŒçš„æ ¼å¼: {', '.join(self.get_supported_formats())}")
            return None
        
        if not os.path.exists(file_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None
        
        print(f"ğŸ“„ å¼€å§‹å¤„ç†æ–‡æ¡£: {file_path}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {os.path.getsize(file_path) / (1024*1024):.2f} MB")
        
        try:
            # æ„å»ºpandocå‘½ä»¤
            cmd = [
                'pandoc',
                file_path,
                '--to', output_format,
                '--wrap', 'none',  # ä¸è‡ªåŠ¨æ¢è¡Œ
                '--standalone',  # ç”Ÿæˆç‹¬ç«‹æ–‡æ¡£
                '--quiet'  # å‡å°‘è¾“å‡º
            ]
            
            print(f"ğŸ”§ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            
            # æ‰§è¡Œpandocè½¬æ¢
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                content = result.stdout
                print(f"âœ… è½¬æ¢æˆåŠŸ: {len(content)} å­—ç¬¦")
                
                # å¦‚æœæ˜¯docxæ–‡ä»¶ï¼Œæå–å›¾ç‰‡å¹¶æ›¿æ¢æ°´å°
                if file_path.lower().endswith('.docx'):
                     print("ğŸ–¼ï¸  æ£€æµ‹åˆ°docxæ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†å›¾ç‰‡...")
                     images = self.extract_images_from_docx(file_path, save_images=True)
                     if images:
                         content = self.replace_image_watermarks(content, images)
                     else:
                         print("â„¹ï¸  æœªæ‰¾åˆ°å›¾ç‰‡æˆ–å›¾ç‰‡å¤„ç†å¤±è´¥")
                
                # æ–°å¢ï¼šå¦‚æœæœ‰æ ¼å¼åˆ†æç»“æœï¼Œå¢å¼ºpandocå†…å®¹
                if hasattr(self, 'special_formatted_text') and self.special_formatted_text:
                    print("ğŸ¨ å¼€å§‹å¢å¼ºæ ¼å¼æ ‡æ³¨...")
                    content = self._enhance_content_with_format_info(content)
                
                # ä¿å­˜è½¬æ¢ç»“æœ
                pandoc_res_dir = Path("pandoc_res")
                pandoc_res_dir.mkdir(exist_ok=True)
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_filename = pandoc_res_dir / f"pandocè½¬æ¢ç»“æœ_{timestamp}.txt"
                with open(output_filename, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"ğŸ“ è½¬æ¢ç»“æœå·²ä¿å­˜åˆ°: {output_filename}")
                
                return content
            else:
                print(f"âŒ è½¬æ¢å¤±è´¥: {result.stderr}")
                return None
                
        except subprocess.TimeoutExpired:
            print("âŒ è½¬æ¢è¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰")
            return None
        except Exception as e:
            print(f"âŒ è½¬æ¢å¼‚å¸¸: {e}")
            return None
    
    def _enhance_content_with_format_info(self, content):
        """æ ¹æ®æ ¼å¼åˆ†æç»“æœå¢å¼ºpandocå†…å®¹"""
        print(f"ğŸ” å¼€å§‹åˆ†æ {len(self.special_formatted_text)} ä¸ªç‰¹æ®Šæ ¼å¼æ–‡æœ¬")
        
        # æŒ‰æ–‡æœ¬é•¿åº¦æ’åºï¼Œä»é•¿åˆ°çŸ­ï¼Œé¿å…çŸ­æ–‡æœ¬æ›¿æ¢å½±å“é•¿æ–‡æœ¬
        sorted_formats = sorted(self.special_formatted_text, 
                              key=lambda x: len(x['text']), reverse=True)
        
        enhanced_count = 0
        
        for format_item in sorted_formats:
            text = format_item['text'].strip()
            formats = format_item['formats']
            
            # è·³è¿‡ç©ºæ–‡æœ¬æˆ–è¿‡çŸ­æ–‡æœ¬
            if len(text) < 2:
                continue
            
            # ç”Ÿæˆæ ¼å¼æ ‡æ³¨
            format_annotation = self._generate_format_annotation(formats)
            
            if format_annotation and text in content:
                # åˆ›å»ºå¢å¼ºçš„æ–‡æœ¬æ ‡æ³¨
                enhanced_text = f"[{text}]{{{format_annotation}}}"
                
                # æ‰§è¡Œæ›¿æ¢ï¼ˆåªæ›¿æ¢ç¬¬ä¸€ä¸ªåŒ¹é…ï¼Œé¿å…é‡å¤æ›¿æ¢ï¼‰
                content = content.replace(text, enhanced_text, 1)
                enhanced_count += 1
                
                print(f"  âœ¨ å¢å¼º: \"{text[:30]}{'...' if len(text) > 30 else ''}\" -> {format_annotation}")
        
        print(f"âœ… æ ¼å¼å¢å¼ºå®Œæˆï¼Œå…±å¤„ç† {enhanced_count} ä¸ªæ–‡æœ¬")
        return content
    
    def _generate_format_annotation(self, formats):
        """æ ¹æ®æ ¼å¼åˆ—è¡¨ç”Ÿæˆæ ‡æ³¨"""
        annotations = []
        
        # å¤„ç†ä¸‹åˆ’çº¿ç±»å‹
        for fmt in formats:
            if "æ³¢æµªçº¿æ ¼å¼" in fmt:
                annotations.append(".wavy-underline")
            elif "ç‚¹çŠ¶çº¿æ ¼å¼" in fmt:
                annotations.append(".dotted-underline")
            elif "ä¸‹åˆ’çº¿: å•ä¸‹åˆ’çº¿" in fmt:
                annotations.append(".single-underline")
            elif "ä¸‹åˆ’çº¿: åŒä¸‹åˆ’çº¿" in fmt:
                annotations.append(".double-underline")
            elif "ä¸‹åˆ’çº¿: ç²—ä¸‹åˆ’çº¿" in fmt:
                annotations.append(".thick-underline")
            elif "ä¸‹åˆ’çº¿: è™šçº¿ä¸‹åˆ’çº¿" in fmt:
                annotations.append(".dashed-underline")
            elif "åˆ é™¤çº¿" in fmt:
                annotations.append(".strikethrough")
            elif "ä¸Šæ ‡" in fmt:
                annotations.append(".superscript")
            elif "ä¸‹æ ‡" in fmt:
                annotations.append(".subscript")
            elif "ç€é‡å·" in fmt:
                annotations.append(".emphasis-mark")
            elif "ç²—ä½“" in fmt:
                annotations.append(".bold")
            elif "æ–œä½“" in fmt:
                annotations.append(".italic")
        
        # å¤„ç†å­—ä½“é¢œè‰²ï¼ˆæå–é¢œè‰²å€¼ï¼‰
        for fmt in formats:
            if "å­—ä½“é¢œè‰²:" in fmt and "000000" not in fmt:  # è·³è¿‡é»‘è‰²
                color = fmt.split("å­—ä½“é¢œè‰²:")[-1].strip()
                annotations.append(f".color-{color}")
        
        # å¤„ç†å­—å·
        for fmt in formats:
            if "å­—å·:" in fmt and "ç£…" in fmt:
                size = fmt.split("å­—å·:")[-1].replace("ç£…", "").strip()
                try:
                    size_num = float(size)
                    if size_num != 12.0:  # è·³è¿‡é»˜è®¤å­—å·
                        annotations.append(f".font-{size}pt")
                except:
                    pass
        
        return " ".join(annotations) if annotations else None
    
    def convert_word_to_markdown(self, file_path):
        """å°†Wordæ–‡æ¡£è½¬æ¢ä¸ºMarkdownæ ¼å¼"""
        return self.convert_word_to_text(file_path, 'markdown')
    
    def convert_word_to_plain_text(self, file_path):
        """å°†Wordæ–‡æ¡£è½¬æ¢ä¸ºçº¯æ–‡æœ¬æ ¼å¼"""
        return self.convert_word_to_text(file_path, 'plain')
    
    def convert_word_to_html(self, file_path):
        """å°†Wordæ–‡æ¡£è½¬æ¢ä¸ºHTMLæ ¼å¼"""
        return self.convert_word_to_text(file_path, 'html')
    
    def call_llm_api(self, content, prompt_template_path="prompt.md"):
        """è°ƒç”¨å¤§æ¨¡å‹APIè§£ææ–‡æ¡£ç»“æ„"""
        print("ğŸ¤– å¼€å§‹è°ƒç”¨å¤§æ¨¡å‹API...")
        
        # è¯»å–promptæ¨¡æ¿
        try:
            with open(prompt_template_path, 'r', encoding='utf-8') as f:
                prompt_template = f.read()
            # ä½¿ç”¨å®‰å…¨çš„å­—ç¬¦ä¸²æ›¿æ¢
            prompt = prompt_template.replace("{content}", content)
            print(f"âœ… æˆåŠŸåŠ è½½promptæ¨¡æ¿: {prompt_template_path}")
        except FileNotFoundError:
            print(f"âš ï¸ æœªæ‰¾åˆ°promptæ¨¡æ¿æ–‡ä»¶: {prompt_template_path}")
            print("ä½¿ç”¨é»˜è®¤prompt...")
            prompt = f"""
ä¸€å¥—è¯•å·æœ‰ä¸‰çº§ç»“æ„ï¼Œ1. åˆ†é¢˜å‹/ç±»å‹çš„å¤§æ¨¡å— 2.å®Œæ•´çš„ä¸€é“é¢˜ 3. å®Œæ•´çš„ä¸€é“é¢˜ä¸­çš„å¤šä¸ªå°é¢˜ã€‚ä½ éœ€è¦è§£æåä¸¤çº§ç»“æ„ã€‚
è¯·åˆ†æä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œæå–å‡ºè¯•å·çš„äºŒçº§ç»“æ„ï¼ˆå®Œæ•´çš„ä¸€é“é¢˜ï¼‰ï¼Œè¿”å›JSONæ ¼å¼çš„æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- total_number: æ€»é¢˜å·ï¼Œå”¯ä¸€ï¼ŒåŠæ­¤é¢˜æŒ‰ç…§è¯•å·é¢˜ç›®å±•ç¤ºé¡ºåºçš„æ€»é¢˜å·ã€‚ï¼ˆå­—ç¬¦ä¸²ï¼‰
- module_number: æ¨¡å—ä¸­çš„é¢˜å·ï¼Œå³åœ¨ä¸€çº§ç»“æ„ä¸­çš„é¢˜å·ã€‚ï¼ˆå­—ç¬¦ä¸²ï¼‰ 
- question_first_sentence: é¢˜ç›®çš„ç¬¬ä¸€ä¸ªåˆ†å¥ï¼ˆå­—ç¬¦ä¸²ï¼‰
- question_page: é¢˜ç›®æ‰€åœ¨çš„é¡µç ï¼ˆintæ•°ç»„ï¼‰
- answer_first_sentence: é¢˜ç›®ç­”æ¡ˆçš„ç¬¬ä¸€ä¸ªåˆ†å¥ï¼ˆå­—ç¬¦ä¸²ï¼Œå¦‚æœæ²¡æœ‰ç­”æ¡ˆåˆ™ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
- explanation_first_sentence: é¢˜ç›®è§£æçš„ç¬¬ä¸€ä¸ªåˆ†å¥ï¼ˆå­—ç¬¦ä¸²ï¼Œå¦‚æœæ²¡æœ‰è§£æåˆ™ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
- answer_page: é¢˜ç›®ç­”æ¡ˆè§£ææ‰€åœ¨çš„é¡µç ï¼ˆintæ•°ç»„ï¼Œå¦‚æœæ²¡æœ‰ç­”æ¡ˆåˆ™ä¸ºnullï¼‰

æ–‡æ¡£å†…å®¹ï¼š
{content}

è¯·åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜æ–‡å­—ã€‚
å¦‚æœé¢˜ç›®/ç­”æ¡ˆè·¨é¡µï¼Œåˆ™åœ¨é¡µç ä¸­éœ€è¦è®°å½•ä¸¤é¡µä¿¡æ¯ã€‚
"""
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # å…ˆæµ‹è¯•APIè¿æ¥
        test_data = {
            "model": "doubao-seed-1-6-250615",
            "messages": [{"role": "user", "content": "Hello"}],
            "max_tokens": 32000,
            "temperature": 0.1,
            "stream": True,
            "thinking": {
                "type": "enabled",
                "budget_tokens": 2000
            }
        }
        
        print("ğŸ” æµ‹è¯•APIè¿æ¥...")
        try:
            test_response = requests.post(
                f"{self.base_url}/v3/chat/completions", 
                headers=headers, 
                json=test_data, 
                timeout=30
            )
            test_response.raise_for_status()
            print("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸ")
        except requests.exceptions.HTTPError as e:
            print(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            print(f"å“åº”çŠ¶æ€ç : {test_response.status_code}")
            print(f"å“åº”å†…å®¹: {test_response.text}")
            return None
        except Exception as e:
            print(f"âŒ APIè¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
            return None
        
        # æ­£å¼è¯·æ±‚ - ä½¿ç”¨æµå¼è¾“å‡º
        data = {
            "model": "doubao-seed-1-6-250615",
            "messages": [{"role": "user", "content": prompt}],
            "stream": True,
            "thinking": {
                "type": "enabled",
                "budget_tokens": 1500
            },
            "response_format": {
                "type": "json_object"
            },
            "temperature": 0.1,
            "max_completion_tokens": 32000
        }
        
        print("ğŸš€ è°ƒç”¨å¤§æ¨¡å‹APIè§£ææ–‡æ¡£ç»“æ„...")
        print(f"è¯·æ±‚URL: {self.base_url}/v3/chat/completions")
        print(f"æ¨¡å‹: {data['model']}")
        print(f"æ¶ˆæ¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        try:
            response = requests.post(
                f"{self.base_url}/v3/chat/completions", 
                headers=headers, 
                json=data, 
                timeout=300,  # å‡å°‘è¶…æ—¶æ—¶é—´åˆ°5åˆ†é’Ÿ
                stream=True
            )
            response.raise_for_status()
            
            # å¤„ç†æµå¼å“åº”
            llm_content = ""
            print("ğŸ“¡ å¼€å§‹æ¥æ”¶æµå¼å“åº”...")
            
            for line in response.iter_lines():
                if line:
                    line = line.decode('utf-8')
                    if line.startswith('data: '):
                        data_str = line[6:]  # å»æ‰ 'data: ' å‰ç¼€
                        
                        if data_str == '[DONE]':
                            print("\nâœ… æµå¼å“åº”æ¥æ”¶å®Œæˆ")
                            break
                        
                        try:
                            data_json = json.loads(data_str)
                            if 'choices' in data_json and len(data_json['choices']) > 0:
                                choice = data_json['choices'][0]
                                
                                # å¤„ç†thinkingçŠ¶æ€
                                if 'thinking' in choice:
                                    thinking = choice['thinking']
                                    if thinking.get('type') == 'thinking':
                                        print(f"ğŸ¤” æ€è€ƒä¸­... ({thinking.get('tokens_used', 0)} tokens)")
                                    elif thinking.get('type') == 'finished':
                                        print(f"âœ… æ€è€ƒå®Œæˆï¼Œå…±ä½¿ç”¨ {thinking.get('tokens_used', 0)} tokens")
                                
                                # å¤„ç†deltaå†…å®¹
                                if 'delta' in choice and 'content' in choice['delta']:
                                    content = choice['delta']['content']
                                    llm_content += content
                                    print(content, end='', flush=True)
                                    
                        except json.JSONDecodeError:
                            continue
            
            print(f"\nâœ… APIè°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(llm_content)} å­—ç¬¦")
            return llm_content
            
        except requests.exceptions.HTTPError as e:
            print(f"HTTPé”™è¯¯: {e}")
            print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"å“åº”å†…å®¹: {response.text}")
            return None
        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    def process_word_document(self, file_path, output_format='markdown', prompt_template_path="prompt.md", 
                            enable_format_analysis=True, enable_dot_below_detection=True):
        """å®Œæ•´çš„Wordæ–‡æ¡£å¤„ç†æµç¨‹"""
        print("=" * 60)
        print("Pandoc Wordæ–‡æ¡£å¤„ç†å·¥å…· - å¢å¼ºç‰ˆ (æ”¯æŒåŠ ç‚¹å­—)")
        print("=" * 60)
        print(f"æ–‡æ¡£æ–‡ä»¶: {file_path}")
        print(f"è¾“å‡ºæ ¼å¼: {output_format}")
        print(f"Promptæ¨¡æ¿: {prompt_template_path}")
        print(f"æ ¼å¼åˆ†æ: {'å¯ç”¨' if enable_format_analysis else 'ç¦ç”¨'}")
        print(f"åŠ ç‚¹å­—æ£€æµ‹: {'å¯ç”¨' if enable_dot_below_detection else 'ç¦ç”¨'}")
        print("=" * 60)
        
        # ğŸ†• æ–°å¢ï¼šç¬¬ä¸€æ­¥ - åŠ ç‚¹å­—é¢„å¤„ç†ï¼ˆå¦‚æœå¯ç”¨ä¸”ä¸ºdocxæ–‡ä»¶ï¼‰
        processed_file_path = file_path
        if enable_dot_below_detection and file_path.lower().endswith('.docx'):
            processed_file_path = self._preprocess_dot_below_chars(file_path)
            if not processed_file_path:
                processed_file_path = file_path  # å›é€€åˆ°åŸæ–‡ä»¶
        
        # ç¬¬äºŒæ­¥ - æ ¼å¼åˆ†æï¼ˆå¦‚æœå¯ç”¨ä¸”ä¸ºdocxæ–‡ä»¶ï¼‰
        format_analysis = None
        if enable_format_analysis and processed_file_path.lower().endswith('.docx'):
            format_analysis = self.extract_format_analysis(processed_file_path)
            if format_analysis:
                self._save_format_analysis(format_analysis, processed_file_path)
        
        # ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨pandocè½¬æ¢æ–‡æ¡£
        content = self.convert_word_to_text(processed_file_path, output_format)
        if not content:
            print("âŒ æ–‡æ¡£è½¬æ¢å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å¤„ç†")
            return None
        
        # ğŸ†• ç¬¬å››æ­¥ï¼šè½¬æ¢åŠ ç‚¹å­—æ ‡è®°ä¸ºHTMLæ ¼å¼
        if enable_dot_below_detection:
            content = self._convert_dot_below_markers_to_html(content)
        
        # ç¬¬ä¸‰æ­¥ï¼šè°ƒç”¨å¤§æ¨¡å‹APIè§£æå†…å®¹
        llm_response = self.call_llm_api(content, prompt_template_path)
        if not llm_response:
            print("âŒ APIè°ƒç”¨å¤±è´¥")
            return None
        
        # ç¬¬å››æ­¥ï¼šå¤„ç†APIå“åº”å¹¶é›†æˆæ ¼å¼ä¿¡æ¯
        api_result = self._process_api_response(llm_response, file_path)
        
        # ç¬¬äº”æ­¥ï¼šå¦‚æœæœ‰æ ¼å¼åˆ†æç»“æœï¼Œå°†å…¶æ•´åˆåˆ°æœ€ç»ˆç»“æœä¸­
        if format_analysis and api_result:
            self._integrate_format_info(api_result, format_analysis, file_path)
        
        return api_result
    
    def _process_api_response(self, llm_content, original_file_path):
        """å¤„ç†APIå“åº”å¹¶ä¿å­˜ç»“æœ"""
        # å»æ‰markdownä»£ç å—æ ‡è®°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if '```json' in llm_content:
            start_idx = llm_content.find('```json') + 7
            end_idx = llm_content.find('```', start_idx)
            if end_idx != -1:
                llm_content = llm_content[start_idx:end_idx]
            else:
                llm_content = llm_content[start_idx:]
        elif '```' in llm_content:
            parts = llm_content.split('```')
            if len(parts) >= 2:
                llm_content = parts[1]
        
        llm_content = llm_content.strip()
        
        # æ£€æµ‹é‡å¤æ¨¡å¼ï¼ˆé˜²æ­¢APIç”Ÿæˆé”™è¯¯ï¼‰
        import re
        # æ£€æµ‹é‡å¤çš„scoreæ¨¡å¼
        if re.search(r'("score"\s*,\s*){3,}', llm_content):
            print("âŒ æ£€æµ‹åˆ°é‡å¤çš„scoreæ¨¡å¼ï¼ŒAPIå“åº”å¼‚å¸¸")
            return None
        
        # æ£€æµ‹å…¶ä»–é‡å¤æ¨¡å¼
        if re.search(r'(\s*,\s*,\s*){3,}', llm_content):
            print("âŒ æ£€æµ‹åˆ°é‡å¤çš„é€—å·æ¨¡å¼ï¼ŒAPIå“åº”å¼‚å¸¸")
            return None
        
        # ä¿®å¤JSONä¸­çš„åŒå¼•å·é—®é¢˜
        # æ›¿æ¢é¢˜ç›®å†…å®¹ä¸­çš„æœªè½¬ä¹‰åŒå¼•å·
        llm_content = re.sub(r'å°†æ•°æ®"([^"]+)"', r'å°†æ•°æ®\\"\\1\\"', llm_content)
        
        # ä¿å­˜åŸå§‹APIå“åº”
        # timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # raw_filename = f"raw_api_response_{timestamp}.txt"
        # with open(raw_filename, 'w', encoding='utf-8') as f:
        #     f.write(llm_content)
        # print(f"ğŸ“„ åŸå§‹APIå“åº”å·²ä¿å­˜åˆ°: {raw_filename}")
        
        # å°è¯•è½¬æ¢ä¸ºJSON
        try:
            questions = json.loads(llm_content)
            
            # åˆ›å»º json_res æ–‡ä»¶å¤¹
            json_res_dir = Path("json_res")
            json_res_dir.mkdir(exist_ok=True)
            
            output_file = json_res_dir / f"questions_with_pandoc_{Path(original_file_path).stem}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(questions, f, ensure_ascii=False, indent=2)
            print(f"ğŸ‰ å®Œæˆï¼å…±{len(questions)}é“é¢˜ç›®ï¼Œä¿å­˜åˆ°: {output_file}")
            return questions
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            print(f"é”™è¯¯ä½ç½®: ç¬¬{e.lineno}è¡Œç¬¬{e.colno}åˆ—")
            print("è¯·æ£€æŸ¥åŸå§‹APIå“åº”æ–‡ä»¶")
            return None
    
    def _preprocess_dot_below_chars(self, docx_path):
        """é¢„å¤„ç†docxæ–‡ä»¶ä¸­çš„åŠ ç‚¹å­—ï¼Œä½¿pandocèƒ½è¯†åˆ«"""
        print("ğŸ” é¢„å¤„ç†åŠ ç‚¹å­—...")
        
        try:
            # å¯¼å…¥é¢„å¤„ç†å™¨
            import zipfile
            import xml.etree.ElementTree as ET
            import tempfile
            import shutil
            import re
            
            output_path = docx_path.replace('.docx', '_dot_processed.docx')
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•æ¥è§£å‹å’Œé‡æ–°æ‰“åŒ…docx
            with tempfile.TemporaryDirectory() as temp_dir:
                extract_dir = Path(temp_dir) / "docx_content"
                extract_dir.mkdir()
                
                # è§£å‹docxæ–‡ä»¶
                with zipfile.ZipFile(docx_path, 'r') as zip_file:
                    zip_file.extractall(extract_dir)
                
                # ä¿®æ”¹document.xml
                document_xml_path = extract_dir / "word" / "document.xml"
                if document_xml_path.exists():
                    with open(document_xml_path, 'r', encoding='utf-8') as f:
                        xml_content = f.read()
                    
                    # æŸ¥æ‰¾å¹¶æ›¿æ¢åŠ ç‚¹å­—æ ‡è®°
                    run_with_em_pattern = r'(<w:r>.*?<w:rPr>.*?)<w:em w:val="dot"\s*/>(.*?</w:rPr>.*?<w:t>)(.*?)(</w:t>.*?</w:r>)'
                    
                    def replace_run_with_em(match):
                        before_em = match.group(1)
                        after_em = match.group(2) 
                        text_content = match.group(3)
                        after_text = match.group(4)
                        
                        # æ·»åŠ ä¸‹åˆ’çº¿å’Œç‰¹æ®Šæ ‡è®°
                        underline_xml = '<w:u w:val="single"/>'
                        marked_text = f"[DOT_BELOW]{text_content}[/DOT_BELOW]"
                        
                        return f"{before_em}{underline_xml}{after_em}{marked_text}{after_text}"
                    
                    modified_content, replacement_count = re.subn(run_with_em_pattern, replace_run_with_em, xml_content, flags=re.DOTALL)
                    
                    if replacement_count > 0:
                        with open(document_xml_path, 'w', encoding='utf-8') as f:
                            f.write(modified_content)
                        print(f"  âœ… å¤„ç†äº† {replacement_count} ä¸ªåŠ ç‚¹å­—")
                
                # é‡æ–°æ‰“åŒ…docxæ–‡ä»¶
                with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                    for file_path in extract_dir.rglob('*'):
                        if file_path.is_file():
                            relative_path = file_path.relative_to(extract_dir)
                            zip_file.write(file_path, relative_path)
            
            return output_path
            
        except Exception as e:
            print(f"  âš ï¸ é¢„å¤„ç†å¤±è´¥: {e}")
            return None
    
    def _convert_dot_below_markers_to_html(self, content):
        """å°†åŠ ç‚¹å­—æ ‡è®°è½¬æ¢ä¸ºHTMLæ ¼å¼"""
        print("ğŸ¨ è½¬æ¢åŠ ç‚¹å­—æ ‡è®°ä¸ºHTMLæ ¼å¼...")
        
        try:
            import re
            
            # åŒ¹é…æ¨¡å¼ï¼š[\[DOT_BELOW\]å­—ç¬¦\[/DOT_BELOW\]]{.underline}
            pattern = r'\[\\\[DOT_BELOW\\\]([\u4e00-\u9fff])\\\[/DOT_BELOW\\\]\]\{\.underline\}'
            
            def replace_with_html(match):
                char = match.group(1)
                return f'<span style="text-emphasis: filled dot black; text-emphasis-position: under right;" data-mce-style="text-emphasis: filled dot black; text-emphasis-position: under right;">{char}</span>'
            
            converted_content, count = re.subn(pattern, replace_with_html, content)
            
            if count > 0:
                print(f"  âœ… è½¬æ¢äº† {count} ä¸ªåŠ ç‚¹å­—ä¸ºHTMLæ ¼å¼")
            
            return converted_content
            
        except Exception as e:
            print(f"  âš ï¸ åŠ ç‚¹å­—è½¬æ¢å¤±è´¥: {e}")
            return content

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # é…ç½®å‚æ•°
    if len(sys.argv) > 1:
        word_file_path = sys.argv[1]
    else:
        word_file_path = "Chinese/ç²¾å“è§£æï¼š2025å¹´ç”˜è‚ƒçœå…°å·å¸‚ä¸­è€ƒè¯­æ–‡çœŸé¢˜ï¼ˆè§£æç‰ˆï¼‰.docx"  # é»˜è®¤æ–‡ä»¶è·¯å¾„
     
    output_format = "markdown"  # å¯é€‰: markdown, plain, html
    prompt_template_path = "prompt_Chinese.md"
    
    # åˆ›å»ºå¤„ç†å™¨å®ä¾‹
    processor = PandocWordProcessor()
    
    # æ£€æŸ¥pandocå¯ç”¨æ€§
    if not processor.pandoc_available:
        print("âŒ Pandocä¸å¯ç”¨ï¼Œè¯·å…ˆå®‰è£…pandoc")
        print("å®‰è£…æ–¹æ³•:")
        print("  macOS: brew install pandoc")
        print("  Ubuntu/Debian: sudo apt-get install pandoc")
        print("  Windows: ä¸‹è½½å®‰è£…åŒ… https://pandoc.org/installing.html")
        return
    
    # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
    if not processor.is_supported_format(word_file_path):
        print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {Path(word_file_path).suffix}")
        print(f"è¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€: {', '.join(processor.get_supported_formats())}")
        return
    
    # å¤„ç†æ–‡æ¡£
    result = processor.process_word_document(
        word_file_path, 
        output_format, 
        prompt_template_path
    )
    
    if result:
        print("âœ… æ–‡æ¡£å¤„ç†å®Œæˆï¼")
        
        # æ˜¾ç¤ºç‰¹æ®Šæ ¼å¼æ‘˜è¦
        format_summary = processor.get_special_format_summary()
        print("\n" + "="*50)
        print(format_summary)
        print("="*50)
    else:
        print("âŒ æ–‡æ¡£å¤„ç†å¤±è´¥")

if __name__ == "__main__":
    main() 